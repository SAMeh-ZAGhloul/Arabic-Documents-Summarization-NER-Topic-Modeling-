{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850ae4c9",
   "metadata": {},
   "source": [
    "# ğŸš€ Arabic Documents Summarization, NER & Topic Modeling\n",
    "\n",
    "## Overview\n",
    "This comprehensive Arabic NLP pipeline combines multiple state-of-the-art models for:\n",
    "- **Text Summarization** (Extractive & Abstractive)\n",
    "- **Named Entity Recognition (NER)** with multiple model comparison\n",
    "- **Sentiment Analysis**\n",
    "- **Topic Modeling** with coherence metrics\n",
    "\n",
    "### Key Features\n",
    "âœ… Multi-model comparison for fair benchmarking  \n",
    "âœ… Automatic evaluation metrics (ROUGE, F1, Coherence)  \n",
    "âœ… Support for both extractive and abstractive summarization  \n",
    "âœ… Arabic text preprocessing and morphological analysis  \n",
    "âœ… Real-world dataset with annotated entities  \n",
    "\n",
    "## Installation & Setup\n",
    "```bash\n",
    "# Install core dependencies\n",
    "pip install camel-tools scikit-learn networkx numpy transformers torch nltk\n",
    "\n",
    "# Download CAMeL Tools data\n",
    "camel_data -i ner-arabert                    # NER (541 MB)\n",
    "camel_data -i sentiment-analysis-arabert     # Sentiment (541 MB)\n",
    "camel_data -i morphology-db-msa-r13          # Morphology (40 MB)\n",
    "camel_data -i disambig-mle-calima-msa-r13    # Disambiguation (88 MB)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94971529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸš€ ARABIC NLP PIPELINE: BENCHMARK EDITION\n",
      "======================================================================\n",
      "  ğŸ“š Loading CAMeL Morphology...\n",
      "  ğŸ·ï¸ Loading NER Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/user/.camel_tools/data/ner/arabert were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“ Loading Summarization Models...\n",
      "  ğŸ“Š Topic Modeling: Gensim\n",
      "\n",
      "======================================================================\n",
      "ğŸ“„ DETAILED ANALYSIS (LARGE DOCS)\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ Document 1 (148 words)\n",
      "ğŸ“ Summarization:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [AraBART]: Ø§Ø¹Ù„Ù†Øª Ø´Ø±ÙƒÙ‡ Ø§Ø±Ø§Ù…ÙƒÙˆ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‡ØŒ Ø¹Ù…Ù„Ø§Ù‚ Ø§Ù„Ù†ÙØ· Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ ÙˆØ§ÙƒØ¨Ø± Ø´Ø±ÙƒÙ‡ Ø·Ø§Ù‚Ù‡ ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù… Ù…Ù† Ø­ÙŠØ« Ø§Ù„Ù‚ÙŠÙ…Ù‡ Ø§Ù„Ø³ÙˆÙ‚ÙŠÙ‡ØŒ Ø§Ù„ÙŠ...\n",
      "ğŸ·ï¸ NER (CAMeL):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Entities found: Ø§Ø±Ø§Ù…ÙƒÙˆ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©, Ø±ÙŠØ§Ù„, Ø§Ù…ÙŠÙ† Ø­Ø³Ù† Ø§Ù„Ù†Ø§ØµØ±, Ø§Ù„Ø¸Ù‡Ø±Ø§Ù†, Ø§Ù„Ù†Ø§ØµØ±, ØªÙˆØªØ§Ù„ Ø§Ù†Ø±Ø¬ÙŠØ²...\n",
      "ğŸ˜Š Sentiment:\n",
      "   True: mixed | Pred: positive\n",
      "\n",
      "ğŸ“‚ Document 2 (88 words)\n",
      "ğŸ“ Summarization:\n",
      "   [AraBART]: Ø§Ø®ØªØªÙ…Øª Ø§Ù„Ù‚Ù…Ù‡ Ø§Ù„Ø¹Ø±Ø¨ÙŠÙ‡ Ø§Ù„Ø·Ø§Ø±Ø¦Ù‡ Ø§Ø¹Ù…Ø§Ù„Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¹Ø§ØµÙ…Ù‡ Ø§Ù„Ø§Ø±Ø¯Ù†ÙŠÙ‡ Ø¹Ù…Ø§Ù†ØŒ ÙˆØ³Ø· Ø­Ø¶ÙˆØ± Ø±ÙÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙˆÙŠ Ù…Ù† Ù‚Ø§Ø¯Ù‡ Ø§Ù„Ø¯ÙˆÙ„ Ø§...\n",
      "ğŸ·ï¸ NER (CAMeL):\n",
      "   Entities found: Ø¹Ù…Ø§Ù†, Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ø§Ù„Ø«Ø§Ù†ÙŠ, Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡, Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù†, Ø¹Ø¨Ø¯Ø§Ù„ÙØªØ§Ø­ Ø§Ù„Ø³ÙŠØ³ÙŠ, Ø³ÙˆØ±ÙŠØ§...\n",
      "ğŸ˜Š Sentiment:\n",
      "   True: neutral | Pred: neutral\n",
      "\n",
      "ğŸ“‚ Document 3 (87 words)\n",
      "ğŸ“ Summarization:\n",
      "   [AraBART]: ØªØ´Ù‡Ø¯ Ø§Ù„Ù…Ù…Ù„ÙƒÙ‡ Ø§Ù„Ø¹Ø±Ø¨ÙŠÙ‡ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ø·ÙØ±Ù‡ ØªÙ‚Ù†ÙŠÙ‡ Ù‡Ø§Ø¦Ù„Ù‡ØŒ Ø­ÙŠØ« Ø§Ø¹Ù„Ù†Øª Ø¬Ø§Ù…Ø¹Ù‡ Ø§Ù„Ù…Ù„Ùƒ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ù„Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙ‚Ù†ÙŠÙ‡ (ÙƒØ§ÙˆØ³Øª...\n",
      "ğŸ·ï¸ NER (CAMeL):\n",
      "   Entities found: Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©, Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡ Ù„Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„ØªÙ‚Ù†ÙŠØ©, ÙƒØ§ÙˆØ³Øª, Ø¬ÙˆØ¬Ù„, ÙˆÙ…Ø§ÙŠÙƒØ±ÙˆØ³ÙˆÙØª, Ø§Ù„Ù…Ù„Ùƒ ÙÙŠØµÙ„ Ø§Ù„ØªØ®ØµØµÙŠ...\n",
      "ğŸ˜Š Sentiment:\n",
      "   True: positive | Pred: positive\n",
      "\n",
      "======================================================================\n",
      "ğŸ† FINAL BENCHMARK SCORES\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ SUMMARIZATION (ROUGE-1)\n",
      "  mT5-XLSum       : 0.2186\n",
      "  Sumy-LexRank    : 0.1873\n",
      "  Sumy-LSA        : 0.1873\n",
      "  AraBART         : 0.1844\n",
      "\n",
      "ğŸ·ï¸ NER (F1 Score)\n",
      "  CAMeL           : 0.8669\n",
      "  Stanza          : 0.7397\n",
      "  Hatmimoha       : 0.7011\n",
      "\n",
      "ğŸ˜Š SENTIMENT ACCURACY: 0.67\n",
      "\n",
      "ğŸ“Š TOPIC COHERENCE: 0.6749\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ğŸ”§ SETUP: Install dependencies and initialize NLTK data\n",
    "This cell downloads all required models and initializes the environment.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "\n",
    "# =============================================\n",
    "# ğŸ› ï¸ SETUP & IMPORTS\n",
    "# =============================================\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except LookupError:\n",
    "    print(\"â¬‡ï¸ Downloading NLTK data...\")\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM, \n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline as hf_pipeline\n",
    ")\n",
    "\n",
    "# CAMeL Tools\n",
    "from camel_tools.utils.normalize import normalize_unicode, normalize_alef_ar, normalize_alef_maksura_ar, normalize_teh_marbuta_ar\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.morphology.database import MorphologyDB\n",
    "from camel_tools.morphology.analyzer import Analyzer\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "\n",
    "# Optional Libraries\n",
    "try:\n",
    "    import sumy\n",
    "    from sumy.parsers.plaintext import PlaintextParser\n",
    "    from sumy.nlp.tokenizers import Tokenizer as SumyTokenizer\n",
    "    from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "    from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "    from sumy.summarizers.lsa import LsaSummarizer\n",
    "    SUMY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SUMY_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import gensim\n",
    "    from gensim import corpora\n",
    "    from gensim.models import LdaModel\n",
    "    from gensim.models.coherencemodel import CoherenceModel\n",
    "    GENSIM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GENSIM_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import stanza\n",
    "    STANZA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    STANZA_AVAILABLE = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE_ID = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "print(f\"âœ… Device: {DEVICE}\")\n",
    "print(f\"âœ… Models: Sumy={SUMY_AVAILABLE}, Gensim={GENSIM_AVAILABLE}, Stanza={STANZA_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837fb8e",
   "metadata": {},
   "source": [
    "## Components & Models\n",
    "\n",
    "### 1. **Text Preprocessing & Normalization**\n",
    "- Unicode normalization\n",
    "- Diacritical mark removal (Tasdeed)\n",
    "- Alef/Maksura/Teh Marbuta standardization\n",
    "- Stopword removal\n",
    "- Lemmatization using CAMeL morphological database\n",
    "\n",
    "### 2. **Named Entity Recognition (NER)**\n",
    "Comparison of 3 models:\n",
    "- **CAMeL Tools (AraBERT)** - Pre-trained on Arabic\n",
    "- **Hatmimoha (BERT)** - BERT-based Arabic NER\n",
    "- **Stanford Stanza** - Multilingual NLP pipeline\n",
    "\n",
    "Entity Types: `PERSON` (PERS), `LOCATION` (LOC), `ORGANIZATION` (ORG), `MISCELLANEOUS` (MISC)\n",
    "\n",
    "### 3. **Text Summarization**\n",
    "**Extractive Methods:**\n",
    "- Sumy-LexRank\n",
    "- Sumy-LSA\n",
    "- Sumy-TextRank\n",
    "\n",
    "**Abstractive Methods:**\n",
    "- mT5-XLSum (multilingual)\n",
    "- AraBART (Arabic-specific)\n",
    "\n",
    "### 4. **Sentiment Analysis**\n",
    "- CAMeL Tools Sentiment Analyzer\n",
    "- Labels: Positive, Negative, Neutral\n",
    "\n",
    "### 5. **Topic Modeling**\n",
    "- Latent Dirichlet Allocation (LDA)\n",
    "- Coherence evaluation (C_V score)\n",
    "- Automatic topic extraction\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c8223",
   "metadata": {},
   "source": [
    "## Metrics & Evaluation\n",
    "\n",
    "### ROUGE Score (Summarization)\n",
    "- **ROUGE-1**: Unigram overlap between reference and hypothesis\n",
    "- **Precision**: Overlap / Hypothesis length\n",
    "- **Recall**: Overlap / Reference length\n",
    "- **F1**: Harmonic mean of precision and recall\n",
    "\n",
    "### NER Metrics\n",
    "- **Precision**: Correct entities / Total predicted entities\n",
    "- **Recall**: Correct entities / Total reference entities\n",
    "- **F1 Score**: Harmonic mean (with partial matching support)\n",
    "\n",
    "### Topic Modeling Metrics\n",
    "- **Coherence (C_V)**: Measures semantic coherence of topics (0-1, higher is better)\n",
    "\n",
    "### Sentiment Accuracy\n",
    "- **Accuracy**: Percentage of correctly predicted sentiment labels\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3a759",
   "metadata": {},
   "source": [
    "## Class Architecture\n",
    "\n",
    "### 1. `EvaluationMetrics`\n",
    "Provides all evaluation functions:\n",
    "- `normalize_arabic()`: Normalize Arabic text for fair comparison\n",
    "- `rouge_scores()`: Calculate ROUGE-1 F1 score\n",
    "- `ner_metrics()`: Calculate NER precision, recall, F1\n",
    "\n",
    "### 2. `ArabicPreprocessor`\n",
    "Handles all text preprocessing:\n",
    "- Loads CAMeL morphological database\n",
    "- Normalizes Unicode and diacriticals\n",
    "- Tokenizes and lemmatizes text\n",
    "- Removes stopwords\n",
    "\n",
    "### 3. `ArabicNER`\n",
    "Multi-model NER comparison:\n",
    "- Loads all 3 models (CAMeL, Hatmimoha, Stanza)\n",
    "- Provides `extract_all()` for parallel extraction\n",
    "- Standardizes output format\n",
    "\n",
    "### 4. `ArabicSummarizer`\n",
    "Combines extractive and abstractive methods:\n",
    "- Loads Sumy models (LexRank, LSA)\n",
    "- Loads neural models (AraBART, mT5-XLSum)\n",
    "- Gracefully handles missing models\n",
    "\n",
    "### 5. `TopicModeler`\n",
    "LDA-based topic extraction:\n",
    "- Preprocesses documents\n",
    "- Builds vocabulary and corpus\n",
    "- Trains LDA model with 3 topics\n",
    "- Calculates coherence score\n",
    "\n",
    "### 6. `UltimatePipeline`\n",
    "Orchestrates the entire workflow:\n",
    "- Initializes all components\n",
    "- Runs analysis on datasets\n",
    "- Aggregates and reports results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144e3d1",
   "metadata": {},
   "source": [
    "## Running the Pipeline\n",
    "\n",
    "Execute the following cell to run the complete benchmark:\n",
    "\n",
    "```python\n",
    "pipeline = UltimatePipeline()\n",
    "pipeline.run(get_large_data())\n",
    "```\n",
    "\n",
    "This will:\n",
    "1. Initialize all NLP models (may take 1-2 minutes for first run)\n",
    "2. Preprocess 3 sample Arabic documents\n",
    "3. Run NER, summarization, sentiment, and topic modeling\n",
    "4. Display detailed results for each document\n",
    "5. Print aggregated benchmark scores\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Execute the complete Arabic NLP pipeline with benchmark evaluation\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = UltimatePipeline()\n",
    "    pipeline.run(get_large_data())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
